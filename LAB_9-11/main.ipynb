{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная часть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 1: Простая линейная регрессия.  \n",
    "Используйте набор данных \"Boston Housing\" из sklearn.datasets. Постройте модель линейной регрессии, сделайте предсказания и вычислите MSE (Mean Squared Error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднеквадратичная ошибка (MSE): 0.555891598695244\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "X = data.data  # Признаки\n",
    "y = data.target  # Целевая переменная (стоимость жилья)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания на тестовой выборке\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Среднеквадратичная ошибка (MSE): {mse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 2: Использование кросс-валидации.  \n",
    "С использованием того же набора данных проведите k-fold кросс-валидацию (k=10) для своей модели и сравните среднее значения MSE на всех фолдах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE на каждом фолде: [0.5590019245025633, 0.5531232970331572, 0.4811612796368561, 0.5742036665176363, 0.4889758378191175, 0.5283881757036769, 0.5511782380281002, 0.47483961298015503, 0.5643692207197094, 0.5500253663196297]\n",
      "Среднее значение MSE: 0.5325266619260601\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Он делит весь набор данных на несколько частей (фолдов), \n",
    "# чтобы модель обучалась на разных подвыборках данных, а \n",
    "# затем тестировалась на оставшихся.\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "mse_values = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    model = LinearRegression()    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_values.append(mse)\n",
    "\n",
    "mean_mse = np.mean(mse_values)\n",
    "\n",
    "print(f\"MSE на каждом фолде: {mse_values}\")\n",
    "print(f\"Среднее значение MSE: {mean_mse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 3: Построение Ridge регрессии.  \n",
    "Примените Ridge регрессию к набору данных \"Boston Housing\". Подберите гиперпараметр `alpha` через кросс-валидацию. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оптимальное значение alpha: 10\n",
      "Среднеквадратичная ошибка (MSE): 0.5550405537343013\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Определение модели Ridge-регрессии\n",
    "ridge = Ridge()\n",
    "\n",
    "# Подбор гиперпараметра alpha через кросс-валидацию\n",
    "param_grid = {'alpha': [0.01, 0.1, 1, 10, 100]}  # Возможные значения alpha\n",
    "grid_search = GridSearchCV(ridge, param_grid, cv=10, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Оптимальное значение alpha\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "print(f\"Оптимальное значение alpha: {best_alpha}\")\n",
    "\n",
    "# Оценка модели с оптимальным alpha\n",
    "best_ridge = Ridge(alpha=best_alpha)\n",
    "best_ridge.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания и вычисление MSE\n",
    "y_pred = best_ridge.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Среднеквадратичная ошибка (MSE): {mse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 4: Построение Lasso регрессии.  \n",
    "Также примените Lasso регрессию к тем же данным. При подборе гиперпараметра `alpha` через кросс-валидацию сравните количество нулевых весов в модели с результатами Ridge регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оптимальное значение alpha для Lasso: 0.001\n",
      "Среднеквадратичная ошибка (MSE) для Lasso: 0.5538940157172418\n",
      "Количество нулевых коэффициентов в Ridge: 0\n",
      "Количество нулевых коэффициентов в Lasso: 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Определение модели Lasso-регрессии\n",
    "lasso = Lasso(max_iter=10000)\n",
    "\n",
    "# Подбор гиперпараметра alpha через кросс-валидацию\n",
    "param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}  # Возможные значения alpha\n",
    "grid_search = GridSearchCV(lasso, param_grid, cv=10, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Оптимальное значение alpha\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "print(f\"Оптимальное значение alpha для Lasso: {best_alpha}\")\n",
    "\n",
    "# Оценка модели с оптимальным alpha\n",
    "best_lasso = Lasso(alpha=best_alpha, max_iter=10000)\n",
    "best_lasso.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания и вычисление MSE\n",
    "y_pred = best_lasso.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Среднеквадратичная ошибка (MSE) для Lasso: {mse}\")\n",
    "\n",
    "# Сравнение количества нулевых весов\n",
    "ridge_coefs = best_ridge.coef_  # Коэффициенты из Ridge-регрессии\n",
    "lasso_coefs = best_lasso.coef_  # Коэффициенты из Lasso-регрессии\n",
    "\n",
    "ridge_zero_weights = np.sum(ridge_coefs == 0)  # Количество нулевых коэффициентов в Ridge\n",
    "lasso_zero_weights = np.sum(lasso_coefs == 0)  # Количество нулевых коэффициентов в Lasso\n",
    "\n",
    "print(f\"Количество нулевых коэффициентов в Ridge: {ridge_zero_weights}\")\n",
    "print(f\"Количество нулевых коэффициентов в Lasso: {lasso_zero_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 5: Использование других функций потерь.  \n",
    "Используйте набор данных diabetes из sklearn.datasets и постройте модель HuberRegressor - линейную модель с функцией потерь Хьюбера, которая менее чувствительна к выбросам по сравнению с MSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднеквадратичная ошибка (MSE): 2913.7072165243917\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "data = load_diabetes(as_frame=True)\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "huber = HuberRegressor(max_iter=1000)\n",
    "\n",
    "huber.fit(X_train, y_train)\n",
    "\n",
    "y_pred = huber.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Среднеквадратичная ошибка (MSE): {mse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 6: Исследование эффекта масштабирования признаков.  \n",
    "Используйте любой набор данных с числовыми признаками. Тренируйте модели Ridge и Lasso регрессии на исходных данных и предобработанных данных (используйте стандартизацию и нормализацию). Сравните коэффициенты моделей, полученных для исходных и предобработанных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сравнение коэффициентов моделей Ridge и Lasso:\n",
      "   Feature  Ridge_Original  Ridge_Standard  Ridge_MinMax  Lasso_Original  Lasso_Standard  Lasso_MinMax\n",
      "    MedInc        0.448511        0.854327      5.704374        0.392693        0.710598      0.282117\n",
      "  HouseAge        0.009726        0.122624      0.505032        0.015081        0.106453      0.000000\n",
      "  AveRooms       -0.123014       -0.294210     -3.066356       -0.000000       -0.000000      0.000000\n",
      " AveBedrms        0.781417        0.339008      6.456633        0.000000        0.000000     -0.000000\n",
      "Population       -0.000002       -0.002282     -0.080924        0.000016       -0.000000     -0.000000\n",
      "  AveOccup       -0.003526       -0.040833     -2.430280       -0.003149       -0.000000     -0.000000\n",
      "  Latitude       -0.419787       -0.896168     -4.165575       -0.114291       -0.011469     -0.000000\n",
      " Longitude       -0.433681       -0.869071     -4.531451       -0.099308       -0.000000     -0.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Создание моделей Ridge и Lasso\n",
    "ridge = Ridge(alpha=1.0)\n",
    "lasso = Lasso(alpha=0.1, max_iter=10000)\n",
    "\n",
    "# Обучение моделей на исходных данных\n",
    "ridge.fit(X_train, y_train)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Коэффициенты для исходных данных\n",
    "ridge_coefs_original = ridge.coef_\n",
    "lasso_coefs_original = lasso.coef_\n",
    "\n",
    "# Стандартизация\n",
    "scaler_standard = StandardScaler()\n",
    "X_train_standard = scaler_standard.fit_transform(X_train)\n",
    "X_test_standard = scaler_standard.transform(X_test)\n",
    "\n",
    "# Нормализация\n",
    "scaler_minmax = MinMaxScaler()\n",
    "X_train_minmax = scaler_minmax.fit_transform(X_train)\n",
    "X_test_minmax = scaler_minmax.transform(X_test)\n",
    "\n",
    "# Обучение моделей на стандартизированных данных\n",
    "ridge.fit(X_train_standard, y_train)\n",
    "lasso.fit(X_train_standard, y_train)\n",
    "\n",
    "# Коэффициенты для стандартизированных данных\n",
    "ridge_coefs_standard = ridge.coef_\n",
    "lasso_coefs_standard = lasso.coef_\n",
    "\n",
    "# Обучение моделей на нормализованных данных\n",
    "ridge.fit(X_train_minmax, y_train)\n",
    "lasso.fit(X_train_minmax, y_train)\n",
    "\n",
    "# Коэффициенты для нормализованных данных\n",
    "ridge_coefs_minmax = ridge.coef_\n",
    "lasso_coefs_minmax = lasso.coef_\n",
    "\n",
    "# Сравнение коэффициентов\n",
    "coefs_comparison = pd.DataFrame({\n",
    "    'Feature': data.feature_names,\n",
    "    'Ridge_Original': ridge_coefs_original,\n",
    "    'Ridge_Standard': ridge_coefs_standard,\n",
    "    'Ridge_MinMax': ridge_coefs_minmax,\n",
    "    'Lasso_Original': lasso_coefs_original,\n",
    "    'Lasso_Standard': lasso_coefs_standard,\n",
    "    'Lasso_MinMax': lasso_coefs_minmax\n",
    "})\n",
    "\n",
    "print(\"Сравнение коэффициентов моделей Ridge и Lasso:\")\n",
    "print(coefs_comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 7: Изучение влияния регуляризации.  \n",
    "Выберите набор данных с высокой размерностью признаков. Создайте модели Lasso и Ridge регрессии. Проведите эксперименты с различными степенями регуляризации и установите, как они влияют на производительность модели и распределение весов признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты экспериментов с регуляризацией:\n",
      " Alpha   Ridge_MSE    Lasso_MSE  Ridge_Nonzero_Coeffs  Lasso_Nonzero_Coeffs\n",
      "  0.01    0.012324     0.010596                   100                    13\n",
      "  0.10    0.015885     0.130142                   100                    10\n",
      "  1.00    0.379046    10.194521                   100                     8\n",
      " 10.00   33.973784   797.072090                   100                     6\n",
      "100.00 1828.130096 31537.044131                   100                     0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Создание набора данных с высокой размерностью\n",
    "X, y = make_regression(n_samples=500, n_features=100, noise=0.1, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Масштабирование данных\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Создание моделей Ridge и Lasso с различными alpha\n",
    "alphas = [0.01, 0.1, 1, 10, 100]\n",
    "results = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    # Ridge-регрессия\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge.fit(X_train_scaled, y_train)\n",
    "    ridge_mse = mean_squared_error(y_test, ridge.predict(X_test_scaled))\n",
    "    \n",
    "    # Lasso-регрессия\n",
    "    lasso = Lasso(alpha=alpha, max_iter=10000)\n",
    "    lasso.fit(X_train_scaled, y_train)\n",
    "    lasso_mse = mean_squared_error(y_test, lasso.predict(X_test_scaled))\n",
    "    \n",
    "    # Сохранение результатов\n",
    "    results.append({\n",
    "        'Alpha': alpha,\n",
    "        'Ridge_MSE': ridge_mse,\n",
    "        'Lasso_MSE': lasso_mse,\n",
    "        'Ridge_Nonzero_Coeffs': np.sum(ridge.coef_ != 0),\n",
    "        'Lasso_Nonzero_Coeffs': np.sum(lasso.coef_ != 0)\n",
    "    })\n",
    "\n",
    "# Создание таблицы с результатами\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Вывод таблицы результатов\n",
    "print(\"Результаты экспериментов с регуляризацией:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Alpha - параметр регуляции. Малые (например 0.1) близки к\n",
    "# обычной линейной регрессии, а большие (например 100.0),\n",
    "# училивают регуляцию\n",
    "\n",
    "# Ridge_MSE - среднеквадратичная ошибка на тестовых данных\n",
    "\n",
    "# Lasso_MSE - среднеквадратичная ошибка на тестовых данных\n",
    "\n",
    "# Ridge_Nonzero_Coeffs - количество ненулевых коэффициентов.\n",
    "# В Ridge все коэффициенты остаются ненулевыми, так как \n",
    "# L2-регуляризация просто уменьшает их значения, но не обнуляет.\n",
    "\n",
    "# Lasso_Nonzero_Coeffs - количество ненулевых коэффициентов.\n",
    "# При малых alpha многие коэффициенты остаются ненулевыми,\n",
    "# но при высоких alpha L1-регуляризация обнуляет большинство \n",
    "# коэффициентов, оставляя только самые важные признаки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 8: Регрессия с использованием метода эластичной сети.  \n",
    "На том же наборе данных обучите ElasticNet, который объединяет L1 и L2 регуляризацию. Экспериментируйте с разными соотношениями L1 и L2 регуляризации и установите, как это влияет на производительность модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты экспериментов с ElasticNet:\n",
      " Alpha  L1_Ratio          MSE  Nonzero_Coeffs\n",
      "  0.01       0.2     3.638783              99\n",
      "  0.01       0.5     1.374089              92\n",
      "  0.01       0.8     0.202768              66\n",
      "  0.10       0.2   287.100299              99\n",
      "  0.10       0.5   117.978598              90\n",
      "  0.10       0.8    18.193626              67\n",
      "  1.00       0.2  7360.107367              97\n",
      "  1.00       0.5  4364.244381              87\n",
      "  1.00       0.8  1151.790695              57\n",
      " 10.00       0.2 25182.465788              81\n",
      " 10.00       0.5 22510.909484              43\n",
      " 10.00       0.8 15464.290292              19\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ElasticNet с различными alpha и l1_ratio\n",
    "alphas = [0.01, 0.1, 1, 10]\n",
    "l1_ratios = [0.2, 0.5, 0.8]\n",
    "\n",
    "results = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    for l1_ratio in l1_ratios:\n",
    "        model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, max_iter=10000, random_state=42)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        nonzero_coefs = np.sum(model.coef_ != 0)\n",
    "        \n",
    "        results.append({\n",
    "            'Alpha': alpha,\n",
    "            'L1_Ratio': l1_ratio,\n",
    "            'MSE': mse,\n",
    "            'Nonzero_Coeffs': nonzero_coefs\n",
    "        })\n",
    "\n",
    "# Создание таблицы с результатами\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Вывод таблицы результатов\n",
    "print(\"Результаты экспериментов с ElasticNet:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Alpha - параметр, регулирующий общую степень регуляризации.\n",
    "# При малых alpha модель более гибках, но склонна к переобучению\n",
    "# При больших alpha модель становится устойчивой к переобучению,\n",
    "# но может терять важные признаки\n",
    "\n",
    "# L1_Ratio\n",
    "# L1_Ratio=0.2: Основной акцент на L2-регуляризации (уменьшение\n",
    "# коэффициентов без обнуления).\n",
    "# L1_Ratio=0.8: Основной акцент на L1-регуляризации (большая \n",
    "# часть коэффициентов обнуляется)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 9: Комбинирование методов отбора признаков и регуляризации.  \n",
    "Выберите подмножество признаков с помощью любого метода отбора признаков, а затем обучите модели с Lasso и Ridge регуляризацией. Сравнивай модели между собой и с моделью, построенной на всех признаках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Model        MSE  Nonzero Coefficients\n",
      "0       Ridge (All)   0.379046                   100\n",
      "1       Lasso (All)   0.130142                    10\n",
      "2  Ridge (Selected)  98.705961                    50\n",
      "3  Lasso (Selected)  93.394648                    42\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Отбор подмножества признаков (например, 50 лучших признаков)\n",
    "k = 50  # Количество лучших признаков\n",
    "selector = SelectKBest(score_func=f_regression, k=k)\n",
    "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
    "X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "# Ridge и Lasso на всех признаках\n",
    "ridge_all = Ridge(alpha=1.0).fit(X_train_scaled, y_train)\n",
    "lasso_all = Lasso(alpha=0.1, max_iter=10000).fit(X_train_scaled, y_train)\n",
    "\n",
    "# Ridge и Lasso на выбранных признаках\n",
    "ridge_selected = Ridge(alpha=1.0).fit(X_train_selected, y_train)\n",
    "lasso_selected = Lasso(alpha=0.1, max_iter=10000).fit(X_train_selected, y_train)\n",
    "\n",
    "# Оценка моделей\n",
    "results = {\n",
    "    \"Model\": [\"Ridge (All)\", \"Lasso (All)\", \"Ridge (Selected)\", \"Lasso (Selected)\"],\n",
    "    \"MSE\": [\n",
    "        mean_squared_error(y_test, ridge_all.predict(X_test_scaled)),\n",
    "        mean_squared_error(y_test, lasso_all.predict(X_test_scaled)),\n",
    "        mean_squared_error(y_test, ridge_selected.predict(X_test_selected)),\n",
    "        mean_squared_error(y_test, lasso_selected.predict(X_test_selected)),\n",
    "    ],\n",
    "    \"Nonzero Coefficients\": [\n",
    "        np.sum(ridge_all.coef_ != 0),\n",
    "        np.sum(lasso_all.coef_ != 0),\n",
    "        np.sum(ridge_selected.coef_ != 0),\n",
    "        np.sum(lasso_selected.coef_ != 0),\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Создание таблицы с результатами\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 10: Использование метрик, устойчивых к выбросам.  \n",
    "Используйте набор данных diabetes из sklearn. и обучите модель HuberRegressor, которая менее чувствительна к выбросам по сравнению с MSE-метрикой. Сравните эту модель с базовой моделью линейной регрессии.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model          MSE        MAE\n",
      "0  Linear Regression  2900.193628  42.794095\n",
      "1    Huber Regressor  2930.844631  42.879734\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import HuberRegressor, LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "data = load_diabetes(as_frame=True)\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Масштабирование данных\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Linear Regression\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train_scaled, y_train)\n",
    "y_pred_linear = linear_model.predict(X_test_scaled)\n",
    "\n",
    "# Huber Regressor\n",
    "huber_model = HuberRegressor(max_iter=1000)\n",
    "huber_model.fit(X_train_scaled, y_train)\n",
    "y_pred_huber = huber_model.predict(X_test_scaled)\n",
    "\n",
    "# Оценка моделей\n",
    "metrics = {\n",
    "    \"Model\": [\"Linear Regression\", \"Huber Regressor\"],\n",
    "    \"MSE\": [\n",
    "        mean_squared_error(y_test, y_pred_linear),\n",
    "        mean_squared_error(y_test, y_pred_huber),\n",
    "    ],\n",
    "    \"MAE\": [\n",
    "        mean_absolute_error(y_test, y_pred_linear),\n",
    "        mean_absolute_error(y_test, y_pred_huber),\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Создание таблицы с результатами\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Вывод результатов\n",
    "print(results_df)\n",
    "\n",
    "# Среднеквадратичная ошибка (MSE):\n",
    "# У Linear Regression MSE чуть ниже (2900.19 против 2930.84),\n",
    "# что означает, что эта модель лучше минимизирует квадраты ошибок.\n",
    "# Однако MSE чувствителен к выбросам, поэтому при наличии выбросов\n",
    "# Linear Regression может давать искусственно завышенные значения предсказаний.\n",
    "\n",
    "# Средняя абсолютная ошибка (MAE):\n",
    "# MAE у обеих моделей практически одинаковый (42.79 и 42.88). \n",
    "# Это показывает, что в среднем отклонения предсказаний от истинных\n",
    "# значений схожи для обеих моделей.\n",
    "# Однако Huber Regressor менее чувствителен к выбросам, поэтому его MAE \n",
    "# остаётся стабильным, даже если в данных есть аномалии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
